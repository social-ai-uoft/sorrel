from gem.utils import (
    updateEpsilon,
    updateMemories,
    findMoveables,
    transferWorldMemories,
    findAgents,
)
from gem.environment.elements.element import EmptyObject, Wall

# from game_utils import createWorld, createWorldImage


# from models.memory import Memory
# from models.dqn import DQN, modelDQN
# from models.randomActions import modelRandomAction
from models.cnn_lstm_dqn import model_CNN_LSTM_DQN

from gemworld.gemsWolves_experimental import WolfsAndGems

# import numpy as np
import matplotlib.pyplot as plt

# import matplotlib.animation as animation
from astropy.visualization import make_lupton_rgb

import torch.nn as nn
import torch.nn.functional as F

# from collections import deque

from DQN_utils import createVideo, save_models, load_models

import random
import torch


save_dir = "/Users/wil/Dropbox/Mac/Documents/gemOutput_experimental/"


def createModels():
    """
    Should make the sequence length of the LSTM part of the model and an input here
    Should also set up so that the number of hidden laters can be added to dynamically
    in this function. Below should fully set up the NN in a flexible way for the studies
    """
    models = []
    # models.append(model_CNN_LSTM_DQN(5, 0.0001, 3000, 650, 325, 75, 4))  # agent model
    models.append(model_CNN_LSTM_DQN(5, 0.0001, 1000, 650, 75, 30, 4))  # agent model
    models.append(model_CNN_LSTM_DQN(5, 0.0001, 1000, 2570, 150, 30, 4))  # wolf model
    return models


worldSize = 15
epochs = 50000
maxTurns = 100

trainableModels = [0, 1]
sync_freq = 500
modelUpdate_freq = 25
epsilon = 0.99

turn = 1

models = createModels()
env = WolfsAndGems(
    height=worldSize,
    width=worldSize,
    layers=1,
    defaultObject=EmptyObject(),
    gem1p=0.03,
    gem2p=0.02,
    wolf1p=0.01,
)
env.gameTest()


def runGame(
    models,
    env,
    turn,
    epsilon,
    epochs=10000,
    maxTurns=100,
):
    losses = 0
    gamePoints = [0, 0]
    for epoch in range(epochs):
        done, withinTurn = 0, 0

        env.reset_env(
            height=worldSize,
            width=worldSize,
            layers=1,
            gem1p=0.03,
            gem2p=0.02,
            wolf1p=0.01,
        )
        for i, j in findMoveables(env.world):
            # reset the memories for all agents
            env.world[i, j, 0].init_replay(3)

        while done == 0:
            turn = turn + 1
            withinTurn = withinTurn + 1

            if epoch % sync_freq == 0:
                for mods in trainableModels:
                    models[mods].model2.load_state_dict(
                        models[mods].model1.state_dict()
                    )

            # note, the input is not working properly to build the sequence for LSTM
            gamePoints = env.step(models, gamePoints, epsilon)

            if withinTurn > maxTurns or len(findAgents(env.world)) == 0:
                done = 1

            if len(trainableModels) > 0:
                # transfer the events for each agent into the appropriate model after all have moved
                env.world = updateMemories(
                    models, env.world, findMoveables(env.world), done, endUpdate=False
                )
                models = transferWorldMemories(
                    models, env.world, findMoveables(env.world)
                )

            if withinTurn % modelUpdate_freq == 0:
                for mods in trainableModels:
                    loss = models[mods].training(150, 0.9)
                    losses = losses + loss.detach().numpy()
        updateEps = False
        if updateEps == True:
            epsilon = updateEpsilon(epsilon, turn, epoch)
        if epoch % 100 == 0 and len(trainableModels) > 0:
            print(epoch, withinTurn, gamePoints, losses, epsilon)
            gamePoints = [0, 0]
            losses = 0
    return models, env, turn, epsilon


"""
TEST SOME MODELS
TODO: Once stable, these should be in a separate file for training models
"""

runParams = (
    [0.9, 1000, 5],
    [0.8, 5000, 5],
    [0.7, 5000, 5],
    [0.2, 5000, 5],
    [0.8, 10000, 25],
    [0.6, 10000, 35],
    [0.2, 10000, 35],
    [0.2, 20000, 50],
)

for modRun in range(len(runParams)):
    models, env, turn, epsilon = runGame(
        models,
        env,
        turn,
        runParams[modRun][0],
        epochs=runParams[modRun][1],
        maxTurns=runParams[modRun][2],
    )
    save_models(models, save_dir, "newWolvesAndAgents" + str(modRun))


"""
SCRIPT TESTNG AREA BELOW
TODO: Once stable these need to be moevd into DQN_utils.py
"""


def makeVideo(filename):
    epoch = 10000
    for video_num in range(5):
        vfilename = (
            save_dir
            + filename
            + "_replayVid_"
            + str(epoch)
            + "_"
            + str(video_num)
            + ".gif"
        )
        createVideo(models, worldSize, 100, env, filename=vfilename)


def replayView(memoryNum, agentNumber, env):
    agentList = findMoveables(env.world)
    i, j = agentList[agentNumber]

    Obj = env.world[i, j, 0]

    state = Obj.replay[memoryNum][0]
    next_state = Obj.replay[memoryNum][3]

    state_RGB = state[:, -1, :, :, :].squeeze().permute(1, 2, 0).numpy()
    image = make_lupton_rgb(
        state_RGB[:, :, 0], state_RGB[:, :, 1], state_RGB[:, :, 2], stretch=0.5
    )

    next_state_RGB = next_state[:, -1, :, :, :].squeeze().permute(1, 2, 0).numpy()
    imageNext = make_lupton_rgb(
        next_state_RGB[:, :, 0],
        next_state_RGB[:, :, 1],
        next_state_RGB[:, :, 2],
        stretch=0.5,
    )

    plt.subplot(1, 2, 1)
    plt.imshow(image)
    plt.subplot(1, 2, 2)
    plt.imshow(imageNext)
    plt.show()


def replayViewModel(memoryNum, modelNumber, models):
    state = models[modelNumber].replay[memoryNum][0]
    next_state = models[modelNumber].replay[memoryNum][3]

    state_RGB = state[:, -1, :, :, :].squeeze().permute(1, 2, 0).numpy()
    image = make_lupton_rgb(
        state_RGB[:, :, 0], state_RGB[:, :, 1], state_RGB[:, :, 2], stretch=0.5
    )

    next_state_RGB = next_state[:, -1, :, :, :].squeeze().permute(1, 2, 0).numpy()
    imageNext = make_lupton_rgb(
        next_state_RGB[:, :, 0],
        next_state_RGB[:, :, 1],
        next_state_RGB[:, :, 2],
        stretch=0.5,
    )

    plt.subplot(1, 2, 1)
    plt.imshow(image)
    plt.subplot(1, 2, 2)
    plt.imshow(imageNext)
    plt.show()
    print(
        models[modelNumber].replay[memoryNum][1],
        models[modelNumber].replay[memoryNum][2],
        models[modelNumber].replay[memoryNum][4],
    )


def createData(env, models, epochs):
    gamePoints = [0, 0]
    env.reset_env(worldSize, worldSize)
    for i, j in findMoveables(env.world):
        env.world[i, j, 0].init_replay(3)
    for _ in range(epochs):
        gamePoints = env.step(models, gamePoints)
    return env


x = findMoveables(env.world)
i, j = x[0]
len(env.world[i, j, 0].replay)


replayViewModel(memoryNum=4, modelNumber=0, models=models)
replayView(memoryNum=4, agentNumber=0, env=env)

for i in range(40):
    replayViewModel(memoryNum=i, modelNumber=0, models=models)

for i in range(40):
    replayView(memoryNum=i, agentNumber=0, env=env)

makeVideo("test")
