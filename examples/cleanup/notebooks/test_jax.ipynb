{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# --------------- #\n",
    "# region: Imports #\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath('../../..')\n",
    "if module_path not in sys.path:\n",
    "  sys.path.insert(0, module_path)\n",
    "# endregion   #\n",
    "# --------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.cleanup.env import Cleanup\n",
    "from examples.cleanup.agents import Agent\n",
    "from examples.RPG.utils import load_config\n",
    "from gem.models.grid_cells import positional_embedding\n",
    "from gem.models.DDQN import doubleDQN\n",
    "from gem.utils import visual_field_sprite, image_from_array, animate, one_hot_encode\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "cfg = load_config(argparse.Namespace(config='../configs/config.yaml'))\n",
    "\n",
    "N_AGENTS = 1\n",
    "agents = []\n",
    "for i in range(N_AGENTS):\n",
    "  agents.append(\n",
    "  Agent(cfg, appearance = cfg.agent.agent.appearance, \n",
    "        model = doubleDQN(\n",
    "        input_size=5224,\n",
    "        number_of_actions=5,\n",
    "        lr=0.001,\n",
    "        gamma=0.97,\n",
    "        per=False,\n",
    "        alpha=0.6,\n",
    "        beta=0.05,\n",
    "        beta_increment=0.0006,\n",
    "        capacity=5000,\n",
    "    )\n",
    "          )\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env = Cleanup(\n",
    "  cfg, agents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "seed = 42\n",
    "rng = jax.random.PRNGKey(seed)\n",
    "\n",
    "# Generate random numbers\n",
    "random_numbers = jax.random.uniform(rng, shape=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Epsilon: 0.8991 - Losses 0 - Avg. last 100 rewards: 0.0\n",
      "Epoch: 10 - Epsilon: 0.8901493517965845 - Losses 0 - Avg. last 100 rewards: 0.2727272727272727\n",
      "Epoch: 20 - Epsilon: 0.8812878083682346 - Losses 581132.9375 - Avg. last 100 rewards: 0.9047619047619048\n",
      "Epoch: 30 - Epsilon: 0.8725144826662403 - Losses 95823.0390625 - Avg. last 100 rewards: 2.0\n",
      "Epoch: 40 - Epsilon: 0.8638284964725682 - Losses 631.8280639648438 - Avg. last 100 rewards: 2.048780487804878\n",
      "Epoch: 50 - Epsilon: 0.8552289803119505 - Losses 14682.884765625 - Avg. last 100 rewards: 2.3333333333333335\n",
      "Epoch: 60 - Epsilon: 0.8467150733648501 - Losses 1084.8265380859375 - Avg. last 100 rewards: 2.2459016393442623\n",
      "Epoch: 70 - Epsilon: 0.8382859233812912 - Losses 454.34765625 - Avg. last 100 rewards: 2.535211267605634\n",
      "Epoch: 80 - Epsilon: 0.8299406865955485 - Losses 322.9467468261719 - Avg. last 100 rewards: 2.5308641975308643\n",
      "Epoch: 90 - Epsilon: 0.8216785276416861 - Losses 749.4376831054688 - Avg. last 100 rewards: 2.5934065934065935\n",
      "Epoch: 100 - Epsilon: 0.8134986194699355 - Losses 232.64907836914062 - Avg. last 100 rewards: 2.66\n",
      "Epoch: 110 - Epsilon: 0.8054001432639079 - Losses 240.0408935546875 - Avg. last 100 rewards: 2.93\n",
      "Epoch: 120 - Epsilon: 0.7973822883586298 - Losses 235.29771423339844 - Avg. last 100 rewards: 3.12\n",
      "Epoch: 130 - Epsilon: 0.7894442521593946 - Losses 650.0484008789062 - Avg. last 100 rewards: 3.05\n",
      "Epoch: 140 - Epsilon: 0.7815852400614219 - Losses 604.9651489257812 - Avg. last 100 rewards: 3.23\n"
     ]
    }
   ],
   "source": [
    "cfg.experiment.epochs = 10000 # override the number of epochs\n",
    "\n",
    "rewards = []\n",
    "losses = 0\n",
    "epsilon = .9\n",
    "\n",
    "EPOCH_PRINT_FREQ = 10\n",
    "EPSILON_DECAY_RATE = 0.999\n",
    "EPSILON_DECAY_FREQ = 1\n",
    "EVAL_EPSILON = 0.5\n",
    "\n",
    "for epoch in range(cfg.experiment.epochs): # note that the language is not right. epoch is training. episode is the game\n",
    "    # Reset the environment at the start of each epoch\n",
    "        env.reset()\n",
    "        for agent in env.agents:\n",
    "            agent.reset()\n",
    "        random.shuffle(agents)\n",
    "\n",
    "        done = 0 \n",
    "        turn = 0\n",
    "        losses = 0\n",
    "        game_points = 0\n",
    "\n",
    "        images = []\n",
    "        if epoch % EPSILON_DECAY_FREQ == 0:\n",
    "            epsilon = epsilon*EPSILON_DECAY_RATE\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            turn = turn + 1\n",
    "\n",
    "            entities = env.get_entities_for_transition()\n",
    "            # Entity transition\n",
    "            for entity in entities:\n",
    "                entity.transition(env)\n",
    "\n",
    "            # Agent transition\n",
    "            for agent in agents:\n",
    "\n",
    "                location_code = positional_embedding(agent.location, env, 3, 3)\n",
    "                direction = one_hot_encode(agent.direction, 4)\n",
    "\n",
    "                # Get current state\n",
    "                state = np.concatenate([agent.pov(env).flatten(), location_code, direction]).reshape(1, -1)\n",
    "\n",
    "                if epoch % EPOCH_PRINT_FREQ == 0:\n",
    "                    _image = visual_field_sprite(env.world)\n",
    "                    image = image_from_array(_image)\n",
    "                    images.append(image)\n",
    "\n",
    "                # Take action based on current state\n",
    "                if epoch % EPOCH_PRINT_FREQ == 0:\n",
    "                    action = agent.model.take_action(state, EVAL_EPSILON)\n",
    "                else:\n",
    "                    action = agent.model.take_action(state, epsilon)\n",
    "\n",
    "                (reward,\n",
    "                next_state,\n",
    "                done_\n",
    "                ) = agent.transition(env, state, action)\n",
    "\n",
    "                if turn >= cfg.experiment.max_turns or done_:\n",
    "                    done = 1\n",
    "\n",
    "                exp = (1, (state, action, reward, next_state, done))\n",
    "                agent.episode_memory.append(exp)\n",
    "                #TODO: decide on memory update procedures\n",
    "                agent.model.replay_buffer.add(torch.tensor(state), action, reward, torch.tensor(next_state), done)\n",
    "\n",
    "                game_points += reward\n",
    "\n",
    "        rewards.append(game_points)\n",
    "        \n",
    "        # At the end of each epoch, train as long as the batch size is large enough.\n",
    "        if epoch > 10:\n",
    "            loss = agent.model.train_step(batch_size = 64)\n",
    "            losses += loss\n",
    "            \n",
    "        # Calculate the average of the last 100 rewards\n",
    "        if len(rewards) >= 100:\n",
    "            avg_last_100_rewards = sum(rewards[-100:]) / 100\n",
    "        else:\n",
    "            avg_last_100_rewards = sum(rewards) / len(rewards)\n",
    "        if epoch % EPOCH_PRINT_FREQ == 0:\n",
    "            print(f'Epoch: {epoch} - Epsilon: {epsilon} - Losses {losses} - Avg. last 100 rewards: {avg_last_100_rewards}')\n",
    "            animate(\n",
    "                images, filename = f\"cleanup_epoch{epoch}\", folder = f\"{cfg.root}/examples/cleanup/data/\"\n",
    "            )\n",
    "            losses = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
