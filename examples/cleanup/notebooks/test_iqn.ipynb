{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# --------------- #\n",
    "# region: Imports #\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath('../../..')\n",
    "if module_path not in sys.path:\n",
    "  sys.path.insert(0, module_path)\n",
    "# endregion   #\n",
    "# --------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.cleanup.env import Cleanup\n",
    "from examples.cleanup.agents import Agent\n",
    "from examples.RPG.utils import load_config\n",
    "from agentarium.embedding import positional_embedding\n",
    "from agentarium.models.DDQN import doubleDQN\n",
    "from agentarium.models.iqn import iRainbowModel\n",
    "from agentarium.utils import visual_field_sprite, image_from_array, animate, one_hot_encode\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "cfg = load_config(argparse.Namespace(config='../configs/config.yaml'))\n",
    "\n",
    "seed = random.randint(1,100)\n",
    "\n",
    "N_AGENTS = 1\n",
    "agents = []\n",
    "for i in range(N_AGENTS):\n",
    "  agents.append(\n",
    "  Agent(cfg, appearance = cfg.agent.agent.appearance, \n",
    "    model = iRainbowModel(\n",
    "      state_size=[8,11,11],\n",
    "      action_size=4,\n",
    "      layer_size=250,\n",
    "      epsilon=.9,\n",
    "      device=\"mps\",\n",
    "      seed=seed,\n",
    "      num_frames=5,\n",
    "      n_step=3,\n",
    "      BATCH_SIZE= 64,\n",
    "      BUFFER_SIZE= 1024,\n",
    "      LR=0.00025,\n",
    "      TAU=.001,\n",
    "      GAMMA=0.95,\n",
    "      N=12,\n",
    "      sync_freq=200,\n",
    "      model_update_freq=4\n",
    "    )\n",
    "          )\n",
    "  )\n",
    "\n",
    "# Set up tensorboard logging\n",
    "if cfg.log:\n",
    "    log_dir = os.path.abspath(f'../runs/{datetime.now().strftime(\"%Y%m%d-%H%m%s\")}/')\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter(\n",
    "        log_dir=log_dir\n",
    "    )\n",
    "\n",
    "\n",
    "env = Cleanup(\n",
    "  cfg, agents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n",
      "torch.Size([968])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m state \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mpov_stack(env)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m EPOCH_EVAL_FREQ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m     _image \u001b[38;5;241m=\u001b[39m \u001b[43mvisual_field_sprite\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworld\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     image \u001b[38;5;241m=\u001b[39m image_from_array(_image)\n\u001b[1;32m     48\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "File \u001b[0;32m~/Documents/GitHub/agentarium/gem/utils.py:316\u001b[0m, in \u001b[0;36mvisual_field_sprite\u001b[0;34m(world, location, vision, tile_size)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     tile_appearance \u001b[38;5;241m=\u001b[39m world[i, j, z]\u001b[38;5;241m.\u001b[39msprite\n\u001b[1;32m    315\u001b[0m     tile_image \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 316\u001b[0m         \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpanduser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_appearance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;241m.\u001b[39mresize(tile_size)\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    319\u001b[0m     )\n\u001b[1;32m    321\u001b[0m tile_image_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(tile_image)\n\u001b[1;32m    322\u001b[0m alpha \u001b[38;5;241m=\u001b[39m tile_image_array[:, :, \u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/PIL/Image.py:3281\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3278\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3281\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3282\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n\u001b[1;32m   3283\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg.experiment.epochs = 4000 # override the number of epochs\n",
    "\n",
    "rewards = []\n",
    "losses = 0\n",
    "epsilon = .9\n",
    "\n",
    "EPOCH_EVAL_FREQ = 50\n",
    "EPSILON_SCHEDULE = [0.9, 0.7, 0.5, 0.3, 0.1, 0.05, 0.05, 0.05, 0.05]\n",
    "EVAL_EPSILON = 0.05\n",
    "\n",
    "for epoch in range(cfg.experiment.epochs): # note that the language is not right. epoch is training. episode is the game\n",
    "    # Reset the environment at the start of each epoch\n",
    "        env.reset()\n",
    "        for agent in env.agents:\n",
    "            agent.reset()\n",
    "            agent.init_replay()\n",
    "            agent.model.start_epoch_action(**locals())\n",
    "        random.shuffle(agents)\n",
    "\n",
    "        epsilon = EPSILON_SCHEDULE[(epoch // 500)]\n",
    "\n",
    "        done = 0 \n",
    "        turn = 0\n",
    "        loss = 0\n",
    "        losses = 0\n",
    "        game_points = 0\n",
    "\n",
    "        images = []\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            turn = turn + 1\n",
    "\n",
    "            entities = env.get_entities_for_transition()\n",
    "            # Entity transition\n",
    "            for entity in entities:\n",
    "                entity.transition(env)\n",
    "\n",
    "            # Agent transition\n",
    "            for agent in agents:\n",
    "\n",
    "                print(agent.pov(env).size())\n",
    "                state = agent.pov_stack(env)\n",
    "\n",
    "                if epoch % EPOCH_EVAL_FREQ == 0:\n",
    "                    _image = visual_field_sprite(env.world)\n",
    "                    image = image_from_array(_image)\n",
    "                    images.append(image)\n",
    "\n",
    "                # Take action based on current state\n",
    "                if epoch % EPOCH_EVAL_FREQ == 0:\n",
    "                    action = agent.model.take_action(state, EVAL_EPSILON)\n",
    "                else:\n",
    "                    action = agent.model.take_action(state, epsilon)\n",
    "\n",
    "                (reward,\n",
    "                next_state,\n",
    "                done_\n",
    "                ) = agent.transition(env, state, action)\n",
    "\n",
    "                if turn >= cfg.experiment.max_turns or done_:\n",
    "                    done = 1\n",
    "\n",
    "                exp = (1, (state, action, reward, next_state, done))\n",
    "                agent.episode_memory.append(exp)\n",
    "                #TODO: decide on memory update procedures\n",
    "                agent.model.end_epoch_action(**locals())\n",
    "\n",
    "                game_points += reward\n",
    "\n",
    "        rewards.append(game_points)\n",
    "        \n",
    "        # At the end of each epoch, train as long as the batch size is large enough.\n",
    "        if epoch > 10:\n",
    "            loss = agent.model.train_model()\n",
    "            losses += loss\n",
    "            \n",
    "        # Calculate the average of the last 100 rewards\n",
    "        if len(rewards) >= 100:\n",
    "            avg_last_100_rewards = sum(rewards[-100:]) / 100\n",
    "        else:\n",
    "            avg_last_100_rewards = sum(rewards) / len(rewards)\n",
    "\n",
    "        if cfg.log:\n",
    "            writer.add_scalar('Loss', loss, epoch)\n",
    "            writer.add_scalar('Reward', game_points, epoch)\n",
    "\n",
    "        if epoch % EPOCH_EVAL_FREQ == 0:\n",
    "            # print(f'Epoch: {epoch} - Epsilon: {epsilon} - Losses {losses} - Avg. last 100 rewards: {avg_last_100_rewards}')\n",
    "            animate(\n",
    "                images, filename = f\"cleanup_epoch{epoch}\", folder = f\"{cfg.root}/examples/cleanup/data/\"\n",
    "            )\n",
    "            losses = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in agents:\n",
    "  agent.model.save(f\"../data/models/{datetime.now().strftime(\"%Y%m%d-%H%m%s\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]], dtype=float32),\n",
       " 0,\n",
       " 0.0,\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]], dtype=float32),\n",
       " 0.0,\n",
       " 1.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from gem.models.DDQN import ClaasyReplayBuffer as Buffer\n",
    "import numpy as np\n",
    "\n",
    "buffer = Buffer(\n",
    "  capacity=100,\n",
    "  obs_shape=(100, )\n",
    ")\n",
    "\n",
    "for i in range(20):\n",
    "  buffer.add(\n",
    "    obs=np.zeros(shape=(100)),\n",
    "    action=0,\n",
    "    reward=0,\n",
    "    done=False\n",
    "  )\n",
    "buffer.add(\n",
    "    obs=np.zeros(shape=(100)),\n",
    "    action=0,\n",
    "    reward=0,\n",
    "    done=True\n",
    ")\n",
    "\n",
    "\n",
    "# S, A, R, S', D, valid\n",
    "tuple( buffer.sample(2, stacked_frames=3)[i][0] for i in range(6) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
