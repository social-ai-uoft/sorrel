{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# --------------- #\n",
    "# region: Imports #\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath('../../..')\n",
    "if module_path not in sys.path:\n",
    "  sys.path.insert(0, module_path)\n",
    "# endregion       #\n",
    "# --------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human player test for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# leakyemotion project imports\n",
    "from examples.leakyemotions.agents import LeakyEmotionAgent, Wolf\n",
    "from examples.leakyemotions.env import LeakyemotionsEnv\n",
    "from examples.leakyemotions.custom_observation_spec import OneHotObservationSpec\n",
    "from examples.leakyemotions.entities import Bush\n",
    "from examples.leakyemotions.wolf_model import WolfModel\n",
    "\n",
    "# sorrel imports\n",
    "from sorrel.config import load_config, argparse\n",
    "from sorrel.models.human_player import HumanPlayer\n",
    "from sorrel.action.action_spec import ActionSpec\n",
    "from sorrel.utils.visualization import (animate, image_from_array,\n",
    "                                        visual_field_sprite)\n",
    "\n",
    "cfg = load_config(argparse.Namespace(config='../configs/config.yaml'))\n",
    "\n",
    "N_AGENTS = 2\n",
    "MAX_TURNS = 100\n",
    "EPSILON_DECAY = 0.0001\n",
    "ENTITY_LIST = [\"EmptyEntity\", \"Wall\", \"Grass\", \"Bush\", \"LeakyEmotionAgent\", \"Wolf\"]\n",
    "\n",
    "agents: list[LeakyEmotionAgent] = []\n",
    "models: list[HumanPlayer] = []\n",
    "\n",
    "world_height = 10\n",
    "world_width = 10\n",
    "spawn_prob = 0.002\n",
    "agent_vision_radius = 2\n",
    "\n",
    "observation_spec = OneHotObservationSpec(\n",
    "            ENTITY_LIST, vision_radius=agent_vision_radius\n",
    "        )\n",
    "observation_spec.override_input_size(\n",
    "    np.array(observation_spec.input_size).reshape(1, -1)\n",
    ")\n",
    "action_spec = ActionSpec([\"up\", \"down\", \"left\", \"right\"])\n",
    "\n",
    "\n",
    "for i in range(N_AGENTS):\n",
    "  models.append(\n",
    "    HumanPlayer(\n",
    "      input_size=[3, cfg.env.height*16, cfg.env.width*16, 4],\n",
    "      action_space=6,\n",
    "      memory_size=1,\n",
    "      show=False\n",
    "    )\n",
    "  )\n",
    "\n",
    "  agents.append(\n",
    "      LeakyEmotionAgent(\n",
    "          observation_spec=observation_spec, action_spec=action_spec, model=models[i], location=None\n",
    "      )\n",
    "  )\n",
    "  agents.append(\n",
    "      Wolf(\n",
    "          observation_spec=observation_spec, action_spec=action_spec, model=WolfModel(1, 4, 1), location=None\n",
    "      )\n",
    "  )\n",
    "  \n",
    "env = LeakyemotionsEnv(\n",
    "        world_height, world_width, spawn_prob, MAX_TURNS, agents)\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "print(env.world.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn taking loop\n",
    "Choose an action from [0, 1, 2, 3, 4, 5] to act on the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please try again. Possible actions are below.\n",
      "[0 1 2 3 4 5]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'action' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWolf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     10\u001b[0m     agent\u001b[38;5;241m.\u001b[39masleep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_turn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/sorrel/sorrel/environments/gridworld.py:141\u001b[0m, in \u001b[0;36mGridworldEnv.take_turn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m agents:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWolf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/sorrel/sorrel/agents/agent.py:135\u001b[0m, in \u001b[0;36mAgent.transition\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Processes a full transition step for the agent.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mThis function does the following:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    env (GridworldEnv): the environment that this agent is acting in.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpov(env)\n\u001b[0;32m--> 135\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(env, action)\n\u001b[1;32m    137\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_done(env)\n",
      "File \u001b[0;32m~/Desktop/sorrel/examples/leakyemotions/agents.py:52\u001b[0m, in \u001b[0;36mLeakyEmotionAgent.get_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     49\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtake_action(model_input)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "File \u001b[0;32m~/Desktop/sorrel/sorrel/models/human_player.py:53\u001b[0m, in \u001b[0;36mHumanPlayer.take_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease try again. Possible actions are below.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43maction\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space:\n\u001b[1;32m     55\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'action' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "while True and not env.game_ended:\n",
    "  img = visual_field_sprite(env)\n",
    "  for i in range(len(img)):\n",
    "    plt.imshow(img[i])\n",
    "    plt.show()\n",
    "  clear_output(wait=True)\n",
    "\n",
    "  for agent in agents:\n",
    "    if agent.kind == \"Wolf\":\n",
    "      agent.asleep = True\n",
    "  \n",
    "  env.take_turn()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
