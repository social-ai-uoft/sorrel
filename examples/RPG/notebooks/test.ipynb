{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# --------------- #\n",
    "# region: Imports #\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath('../../..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "# endregion       #\n",
    "# --------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4. Total training duration: 4.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rgelpi/Documents/GitHub/transformers/examples/RPG/notebooks/test.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rgelpi/Documents/GitHub/transformers/examples/RPG/notebooks/test.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39margparse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rgelpi/Documents/GitHub/transformers/examples/RPG/notebooks/test.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m cfg \u001b[39m=\u001b[39m load_config(argparse\u001b[39m.\u001b[39mNamespace(config\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../config.yaml\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rgelpi/Documents/GitHub/transformers/examples/RPG/notebooks/test.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_transformer_model(cfg, \u001b[39m'\u001b[39;49m\u001b[39miRainbowModel_20230916-17091694900425\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/transformers/examples/RPG/test.py:260\u001b[0m, in \u001b[0;36mtrain_transformer_model\u001b[0;34m(cfg, action_model_pattern)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10000\u001b[39m):\n\u001b[1;32m    259\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 260\u001b[0m     state_loss, action_loss \u001b[39m=\u001b[39m inverse_model\u001b[39m.\u001b[39;49mtrain_model()\n\u001b[1;32m    261\u001b[0m     state_predictions, state_targets \u001b[39m=\u001b[39m inverse_model\u001b[39m.\u001b[39mplot_trajectory()\n\u001b[1;32m    263\u001b[0m     \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39mlog:\n",
      "File \u001b[0;32m~/Documents/GitHub/transformers/gem/models/transformer.py:572\u001b[0m, in \u001b[0;36mVisionTransformer.train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    569\u001b[0m loss \u001b[39m=\u001b[39m state_loss \u001b[39m+\u001b[39m action_loss\n\u001b[1;32m    571\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 572\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    573\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m state_loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem(), action_loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from examples.RPG.test import train_transformer_model\n",
    "from examples.RPG.utils import load_config\n",
    "import argparse\n",
    "\n",
    "cfg = load_config(argparse.Namespace(config='../config.yaml'))\n",
    "\n",
    "train_transformer_model(cfg, 'iRainbowModel_20230916-17091694900425')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ViTOneHot.__init__() missing 2 required positional arguments: 'memory' and 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rgelpi/Documents/GitHub/transformers/examples/RPG/notebooks/test.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rgelpi/Documents/GitHub/transformers/examples/RPG/notebooks/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgem\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m load_config\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rgelpi/Documents/GitHub/transformers/examples/RPG/notebooks/test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cfg \u001b[39m=\u001b[39m load_config(argparse\u001b[39m.\u001b[39mNamespace(config\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../configs/transformer.yaml\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rgelpi/Documents/GitHub/transformers/examples/RPG/notebooks/test.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m ViTOneHot(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mvars\u001b[39;49m(cfg\u001b[39m.\u001b[39;49mmodel))\n",
      "\u001b[0;31mTypeError\u001b[0m: ViTOneHot.__init__() missing 2 required positional arguments: 'memory' and 'seed'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from gem.models.transformer import ViTOneHot\n",
    "from gem.config import load_config\n",
    "\n",
    "cfg = load_config(argparse.Namespace(config='../configs/transformer.yaml'))\n",
    "\n",
    "model = ViTOneHot(**vars(cfg.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
