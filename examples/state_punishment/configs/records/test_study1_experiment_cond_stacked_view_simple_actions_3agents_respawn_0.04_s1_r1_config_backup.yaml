
experiment:
  name: state_punishment_beta
  epochs: 2000000
  max_turns: 100
  epsilon_decay: 0.0001

env:
  height: 15
  width: 15
  layers: 1
  channels: 10
  default_object: EmptyObject
  full_mdp: False # Whether to return the full agent # the result is not normal when True
  tile_size: [16, 16] # Default sprite size for visualization (not used as model input yet) [16, 16]
  prob:
    item_spawn: 0.2 # 0.1 #0.15 # Initial item spawn rate. Later rate is lower as otherwise the entire map gets overwhelmed.
    # item_choice: [0.1, 0.3, 0.4, 0.2] # gem, coin, food, bone
    item_choice: [0.25, 0.25, 0.25, 0.125, 0.125] # [0.3, 0.7] [0.8, 0.2]
    respawn_rate: 0.04
  entity_names: ['A', 'B', 'C', 'D', 'E', 'Wall']

state_sys:
  resource_punishment_is_ambiguous: True
  only_punish_taboo: False
  prob_list: 
    Gem: 0.0
    Coin: 0.0
    Bone: 1.
  init_prob: 0.
  magnitude: 14  # 20 # positive - punishment, negative - reward 
  taboo: ['D', 'E']
  potential_taboo: ['A', 'B', 'C', 'D', 'E']
  change_per_vote: 0.2 # 0.25
  max_level: 9
  num_resources: 5
  num_steps: 10
  intercept: 0.0
  slope: 0.01
  weight: 0.9
  intercept_increment: 0.05
  upper_bound: [0.2, 0.4, 0.55, 0.85, 1.0]
  rewards: [4, 6, 8, 10, 12]
  resources: ['A', 'B', 'C', 'D', 'E']




model:
  iqn:
    type: iRainbowModel
    num: 3
    device: cpu
    parameters:
      state_size: [6, 10, 7, 7] # If full_mdp is True, this is [channels, height, width]. If not, this is [channels, 2 * vision + 1, 2 * vision + 1]
      extra_percept_size: 2 # added for extra percept
      action_size: 6
      layer_size: 250 # 250
      num_frames: 5
      n_step: 3
      BATCH_SIZE: 64
      BUFFER_SIZE: 1024
      LR: 0.00025
      TAU: .001
      GAMMA: 0.99
      N: 12
      sync_freq: 200
      model_update_freq: 4
      epsilon: 0.01

agent:
  agent:
    num: 3
    model: iqn
    num_memories: 5 # Should match num_frames in the model above
    vision: 3
    # appearance: (0.0, 0.0, 255.0)
    appearance: 
      - [0.0, 0.0, 255.0, 255.0, 0., 0.0, 0.0, 0.0, 0.0, 0.0]
      - [0.0, 0.0, 255.0, 0., 255., 0.0, 0.0, 0.0, 0.0, 0.0]
      - [0.0, 0.0, 255.0, 0.0, 0.0, 255., 0., 0.0, 0.0, 0.0]
      - [0.0, 0.0, 255.0, 0.0, 0.0, 0., 255., 0.0, 0.0,  0.0]
      - [0.0, 0.0, 255.0, 0.0, 0., 0.0, 0., 255., 0.0, 0.0]
      - [0.0, 0.0, 255.0, 0.0, 0., 0.0, 0., 0., 255.0, 0.0]
      - [0.0, 0.0, 255.0, 0.0, 0., 0.0, 0., 0., 0.0, 255., 0.0]
    memory_size: 100 # If this is larger than max_turns above, could cause issues
    # Not used right now
    tile_size: (1, 1)
    pov_size: 9
    health: 10
    extra_percept_size: 2 # added for extra percept

entity:
  # Gem:
  #   start_num: 1
  #   value: 1 # 5
  #   appearance: (0.0, 255.0, 0.0) # Green
  #   social_harm: 0
  # Coin:
  #   start_num: 1
  #   value: 5 # 2 #10
  #   appearance: (255.0, 0.0, 0.0) # Yellow
  #   social_harm: 0 # 5
  # # Food:
  # #   start_num: 0
  # #   value: 1
  # #   appearance: (255.0, 0.0, 0.0) # Red
  # Bone:
  #   start_num: 1
  #   value: 10
  #   appearance: (0, 0, 0) # Black
  #   social_harm: 40 # 5
  A:
    start_num: 1
    value: 4
    appearance: (0.0, 0.0, 255.0)
    social_harm: 0
  B:
    start_num: 1
    value: 6
    appearance: (0.0, 0.0, 255.0)
    social_harm: 0
  C:
    start_num: 1
    value: 8
    appearance: (0.0, 0.0, 255.0)
    social_harm: 0
  D:
    start_num: 1
    value: 10
    appearance: (0.0, 0.0, 255.0)
    social_harm: 40
  E:
    start_num: 1
    value: 12
    appearance: (0.0, 0.0, 255.0)
    social_harm: 40

# Not used right now
replay:
  use_sprites: False
  save: True
  replay_frequency: 500
  num_replays: 3
  end_update: True
  epsilon: 0.01
  blit: False
  fps: 2
  turns: 100

# Root folder for accessing file structure and modules
root: '/Users/socialai/Documents/state_punishment'
seed: 1
log: True
random: False
state_mode: 'composite'
action_mode: 'simple'
load_weights: False
with_direct_cost: 0.0

exp_name: 'test_study1_experiment_cond_stacked_view_simple_actions_3agents_respawn_0.04_s1_r1'
# stacked_views,single_view
