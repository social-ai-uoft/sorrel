{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yikaitang/Documents/GitHub/puppet_training/examples/puppet_training/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "not train partners\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (224,) into shape (1568,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 103\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# agent.model.load(\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m#      '../models/checkpoints/fixed_punishment_rate_1.0_oneAs_size15_init_spawn_0.2_agent0_iRainbowModel.pkl'\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# agent.model.epsilon = 0.01\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Reset the environment at the start of each epoch\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m         images_anim \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;66;03m# for agent in env.agents:\u001b[39;00m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;66;03m#     agent.reset(env)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/puppet_training/examples/puppet_training/env.py:68\u001b[0m, in \u001b[0;36mpuppet_training.reset\u001b[0;34m(self, state_mode)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulate()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n\u001b[0;32m---> 68\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/puppet_training/examples/puppet_training/agents.py:206\u001b[0m, in \u001b[0;36mAgent.reset\u001b[0;34m(self, env, state_mode)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, env: GridworldEnv, state_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_replay\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencounters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGem\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    214\u001b[0m     }\n",
      "File \u001b[0;32m~/Documents/GitHub/puppet_training/examples/puppet_training/agents.py:60\u001b[0m, in \u001b[0;36mAgent.init_replay\u001b[0;34m(self, env, state_mode)\u001b[0m\n\u001b[1;32m     58\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_frames):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/puppet_training/agentarium/buffers.py:71\u001b[0m, in \u001b[0;36mClaasyReplayBuffer.add\u001b[0;34m(self, obs, action, reward, done)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs, action, reward, done):\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    Add an experience to the replay buffer.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m        done (bool): Whether the episode terminated after this step.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx] \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx] \u001b[38;5;241m=\u001b[39m action\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx] \u001b[38;5;241m=\u001b[39m reward\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (224,) into shape (1568,)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# --------------- #\n",
    "# region: Imports #\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath('../../..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "# endregion       #\n",
    "# --------------- #\n",
    "\n",
    "from examples.puppet_training.utils import (\n",
    "    init_log, parse_args, load_config,\n",
    "    create_models,\n",
    "    create_agents,\n",
    "    create_entities,\n",
    ")\n",
    "from examples.puppet_training.env import puppet_training\n",
    "from agentarium.logging_utils import GameLogger\n",
    "from agentarium.models import human_player\n",
    "from agentarium.utils import visual_field_sprite, image_from_array\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "config_path = '../configs/records/puppet_training_full_partner_selection_env_fixed_config_backup.yaml'\n",
    "\n",
    "cfg = load_config(argparse.Namespace(config=config_path))\n",
    "\n",
    "# set seed \n",
    "cfg.seed = 12\n",
    "random.seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "torch.manual_seed(cfg.seed)\n",
    "torch.cuda.manual_seed_all(cfg.seed)\n",
    "cfg.exp_name = cfg.exp_name + f'_seed{cfg.seed}'\n",
    "\n",
    "\n",
    "models_agent = create_models(cfg)\n",
    "agents = create_agents(cfg, models_agent)\n",
    "\n",
    "# change agent attribute\n",
    "for agent in agents:\n",
    "    if agent.ixs == 0:\n",
    "        agent.role = 'decider'\n",
    "    else:\n",
    "        agent.role = 'partner'\n",
    "    agent.value_dict = {'Gem': 2, 'Bone': 2, 'Coin': 2, 'Agent': 0, 'Wall':-1, 'EmptyObject':0}\n",
    "\n",
    "# assign roles\n",
    "if not cfg.train_partners:\n",
    "    print('not train partners')\n",
    "    for agent in agents:\n",
    "        if agent.ixs == 0:\n",
    "            agent.role = 'decider'\n",
    "            agent.can_see_others_worldview = True\n",
    "        else:\n",
    "            agent.role = 'partner'\n",
    "            agent.can_see_others_worldview = False\n",
    "        if agent.ixs == 1:\n",
    "            agent.resource_val = {'median': {'Gem': 2, 'Bone': 2, 'Coin': 2, 'Agent': 0, 'Wall':-1, 'EmptyObject':0},\n",
    "            'var': {'Gem': 3, 'Bone': 3, 'Coin': 3, 'Agent': 0, 'Wall':0, 'EmptyObject':0}}\n",
    "        elif agent.ixs == 2:\n",
    "            agent.resource_val = {'median': {'Gem': 2, 'Bone': 2, 'Coin': 2, 'Agent': 0, 'Wall':-1, 'EmptyObject':0},\n",
    "            'var': {'Gem': 0, 'Bone': 0, 'Coin': 0, 'Agent': 0, 'Wall':0, 'EmptyObject':0}}\n",
    "else:\n",
    "    for agent in agents:\n",
    "        agent.role = 'decider'\n",
    "        agent.can_see_others_worldview = False\n",
    "        agent.resource_val = {'median': {'Gem': 2, 'Bone': 2, 'Coin': 2, 'Agent': 0, 'Wall':-1, 'EmptyObject':0},\n",
    "        'var': {'Gem': 0, 'Bone': 0, 'Coin': 0, 'Agent': 0, 'Wall':0, 'EmptyObject':0}}\n",
    "\n",
    "entities = create_entities(cfg)\n",
    "env = puppet_training(cfg, agents, entities, is_partner_selection_env=True)\n",
    "env.full_partner_selection = True\n",
    "\n",
    "for ixs, agent in enumerate(agents):\n",
    "    # agent.model = human_player.ModelHumanPlayer(\n",
    "    #      action_space=4, \n",
    "    #      state_size = cfg.model.iqn.parameters.state_size, \n",
    "    #      extra_percept_size = cfg.model.iqn.parameters.extra_percept_size,\n",
    "    #      memory_size=1, \n",
    "    #      name=f'human {ixs}')\n",
    "\n",
    "    # agent.model = models_agent[0]\n",
    "    \n",
    "    agent.model.load(\n",
    "        #  f'../models/checkpoints/puppet_training_only_partners_env_agent{0}_iRainbowModel.pkl')\n",
    "        f'../models/checkpoints/puppet_training_full_partner_selection_env_fixed_agent{agent.ixs}_iRainbowModel.pkl')\n",
    "    # agent.model.load(\n",
    "    #      '../models/checkpoints/fixed_punishment_rate_1.0_oneAs_size15_init_spawn_0.2_agent0_iRainbowModel.pkl'\n",
    "    # )\n",
    "    # agent.model.epsilon = 0.01\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "    # Reset the environment at the start of each epoch\n",
    "        env.reset()\n",
    "        images_anim = []\n",
    "        # for agent in env.agents:\n",
    "        #     agent.reset(env)\n",
    "        random.shuffle(agents)\n",
    "\n",
    "        scores = GameLogger(max_epochs=1)\n",
    "\n",
    "        done = 0 \n",
    "        turn = 0\n",
    "        losses = 0\n",
    "        game_points = [0 for _ in range(len(agents))]\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # env.check_and_close_gate()\n",
    "\n",
    "            turn = turn + 1\n",
    "\n",
    "            entities = env.get_entities_for_transition()\n",
    "            # Entity transition\n",
    "            for entity in entities:\n",
    "                entity.transition(env)\n",
    "\n",
    "            img = visual_field_sprite(env.world, tile_size = env.tile_size)\n",
    "            clear_output(wait = True)\n",
    "            # scores.pretty_print(\n",
    "            #      'jupyter-mode',\n",
    "            #      epoch = epoch,\n",
    "            #      turn = turn,\n",
    "            #      reward = game_points,\n",
    "            # )\n",
    "            \n",
    "            img = image_from_array(img)\n",
    "            time.sleep(0.1)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            images_anim.append(img)\n",
    "            print(game_points)\n",
    "\n",
    "\n",
    "            # Agent transition\n",
    "            for agent in agents:\n",
    "\n",
    "                (state,\n",
    "                action,\n",
    "                reward,\n",
    "                next_state,\n",
    "                done_\n",
    "                ) = agent.transition(env)\n",
    "\n",
    "                img = visual_field_sprite(env.world, tile_size = env.tile_size)\n",
    "                img = image_from_array(img)\n",
    "                # print(agent.model.name)\n",
    "                # plt.imshow(img)\n",
    "                plt.show()\n",
    "                # if agent.ixs == 0:\n",
    "                #      images_anim.append(img)\n",
    "\n",
    "                if turn >= cfg.experiment.max_turns or done_:\n",
    "                    done = 1\n",
    "\n",
    "                game_points[agent.ixs] += reward\n",
    "\n",
    "            env.check_and_close_gate()\n",
    "\n",
    "print(agent.encounters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# --------------- #\n",
    "# region: Imports #\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath('../../..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "# endregion       #\n",
    "# --------------- #\n",
    "\n",
    "from examples.puppet_training.utils import (\n",
    "    init_log, parse_args, load_config,\n",
    "    create_models,\n",
    "    create_agents,\n",
    "    create_entities,\n",
    ")\n",
    "config_path = '../configs/config_fixed_rate_no_vote.yaml'\n",
    "from examples.puppet_training import agents, entities\n",
    "from examples.puppet_training.env import puppet_training\n",
    "from examples.puppet_training.utils import inspect_the_env\n",
    "from agentarium.logging_utils import GameLogger\n",
    "from agentarium.models import human_player\n",
    "from agentarium.utils import visual_field_sprite, image_from_array\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "cfg = load_config(argparse.Namespace(config=config_path))\n",
    "\n",
    "models = create_models(cfg)\n",
    "agents = create_agents(cfg, models)\n",
    "entities = create_entities(cfg)\n",
    "env = puppet_training(cfg, agents, entities)\n",
    "\n",
    "# instantiate the performance logger\n",
    "performance = []\n",
    "\n",
    "# change value of the entity\n",
    "reward_set = [1, 0, 0]\n",
    "for entity in env.entities:\n",
    "    if entity.name == 'Gem':\n",
    "        entity.value = reward_set[0]\n",
    "    elif entity.name == 'Bone':\n",
    "        entity.value = reward_set[1]\n",
    "    elif entity.name == 'Coin':\n",
    "        entity.value = reward_set[2]\n",
    "\n",
    "\n",
    "\n",
    "for ixs, agent in enumerate(agents):\n",
    "    agent.model = human_player.ModelHumanPlayer(\n",
    "         action_space=8, \n",
    "         state_size = cfg.model.iqn.parameters.state_size, \n",
    "         extra_percept_size = cfg.model.iqn.parameters.extra_percept_size,\n",
    "         memory_size=1, \n",
    "         name=f'human {ixs}')\n",
    "    # agent.model.load(\n",
    "    #      f'../models/checkpoints/fixed_punishment_rate_0.75_twoAs_extra_percept_v2_higher_harm_gem_has_value_save_model_agent{ixs}_iRainbowModel_20241127-04111732699956.pkl')\n",
    "    # agent.model.load(\n",
    "    #      '../models/checkpoints/fixed_punishment_rate_1.0_oneAs_size15_init_spawn_0.2_agent0_iRainbowModel.pkl'\n",
    "    # )\n",
    "    # agent.model.epsilon = 0.01\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "    # Reset the environment at the start of each epoch\n",
    "    env.reset()\n",
    "    images_anim = []\n",
    "    # for agent in env.agents:\n",
    "    #     agent.reset(env)\n",
    "    random.shuffle(agents)\n",
    "\n",
    "    scores = GameLogger(max_epochs=1)\n",
    "    \n",
    "    env.cache['harm'] = [0 for _ in range(len(agents))]\n",
    "\n",
    "    done = 0 \n",
    "    turn = 0\n",
    "    losses = 0\n",
    "    game_points = [0 for _ in range(len(agents))]\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        turn = turn + 1\n",
    "\n",
    "        entities = env.get_entities_for_transition()\n",
    "        # Entity transition\n",
    "        for entity in entities:\n",
    "            entity.transition(env)\n",
    "\n",
    "        img = visual_field_sprite(env.world, tile_size = env.tile_size)\n",
    "        clear_output(wait = True)\n",
    "        # scores.pretty_print(\n",
    "        #      'jupyter-mode',\n",
    "        #      epoch = epoch,\n",
    "        #      turn = turn,\n",
    "        #      reward = game_points,\n",
    "        # )\n",
    "        \n",
    "        img = image_from_array(img)\n",
    "        time.sleep(0.1)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        images_anim.append(img)\n",
    "        print(game_points)\n",
    "\n",
    "\n",
    "        # Agent transition\n",
    "        for agent in agents:\n",
    "\n",
    "            (state,\n",
    "            action,\n",
    "            reward,\n",
    "            next_state,\n",
    "            done_\n",
    "            ) = agent.transition(env)\n",
    "\n",
    "            img = visual_field_sprite(env.world, tile_size = env.tile_size)\n",
    "            img = image_from_array(img)\n",
    "            # print(agent.model.name)\n",
    "            # plt.imshow(img)\n",
    "            plt.show()\n",
    "            # if agent.ixs == 0:\n",
    "            #      images_anim.append(img)\n",
    "\n",
    "            if turn >= cfg.experiment.max_turns or done_:\n",
    "                done = 1\n",
    "\n",
    "            exp = (1, (state, action, reward, next_state, done))\n",
    "            # agent.episode_memory.append(exp)\n",
    "\n",
    "            game_points[agent.ixs] += reward\n",
    "\n",
    "            print(agent.location)\n",
    "\n",
    "        img = visual_field_sprite(env.world, tile_size = env.tile_size)\n",
    "        clear_output(wait = True)\n",
    "        img = image_from_array(img)\n",
    "        time.sleep(0.1)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    # record the performance of the agents\n",
    "    total_encounters = {entity:0 for entity in vars(cfg.entity)}\n",
    "    for agent in agents:\n",
    "        for entity in vars(cfg.entity):\n",
    "            total_encounters[entity] += agent.encounters[entity]\n",
    "\n",
    "    performance[reward_set] = total_encounters\n",
    "\n",
    "    # print the performance of the agents\n",
    "    for reward_set, encounters in performance.items():\n",
    "        print('==========================')\n",
    "        print(f\"Reward set: {reward_set}\")\n",
    "        for entity, count in encounters.items():\n",
    "            print(f\"{entity}: {count}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imageio.v3 as iio\n",
    "def create_gif_from_arrays(image_arrays, output_path, duration=100, loop=0):\n",
    "    \"\"\"\n",
    "    Create a GIF from a sequence of images in NumPy array format.\n",
    "\n",
    "    Args:\n",
    "        image_arrays (list of np.ndarray): Sequence of images as NumPy arrays.\n",
    "        output_path (str): Path to save the output GIF.\n",
    "        duration (int): Duration of each frame in milliseconds (controls speed).\n",
    "        loop (int): Number of times the GIF should loop (0 for infinite).\n",
    "    \"\"\"\n",
    "    # Convert NumPy arrays to PIL Images\n",
    "    if type(image_arrays[0]) != Image.Image:\n",
    "        pil_images = [Image.fromarray(img) for img in image_arrays]\n",
    "    else:\n",
    "        pil_images = image_arrays\n",
    "    \n",
    "    # Save as GIF\n",
    "    pil_images[0].save(\n",
    "        output_path,\n",
    "        save_all=True,\n",
    "        append_images=pil_images[1:],\n",
    "        duration=duration,\n",
    "        loop=loop\n",
    "    )\n",
    "    print(f\"GIF saved at {output_path}\")\n",
    "\n",
    "\n",
    "def create_gif_iio(images, output_path, fps=10):\n",
    "    \"\"\"\n",
    "    Create a GIF from a list of image arrays using `imageio`.\n",
    "\n",
    "    Args:\n",
    "        images (list of numpy.ndarray): A list of image arrays (e.g., RGB or grayscale).\n",
    "        output_path (str): Path to save the generated GIF.\n",
    "        fps (int): Frames per second, controlling the speed of the GIF.\n",
    "    \"\"\"\n",
    "    # Calculate the duration per frame in seconds\n",
    "    duration_per_frame = 1 / fps\n",
    "    \n",
    "    # Save the GIF\n",
    "    iio.imwrite(output_path, images, format=\"GIF\", duration=duration_per_frame)\n",
    "    print(f\"GIF saved at {output_path}\")\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def create_gif_from_pil_force_clean(image_list, output_path, duration=100, loop=0, background_color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Create a GIF from a list of `PIL.Image.Image` objects, ensuring no shadow artifacts.\n",
    "    Ensures each frame has a fresh background.\n",
    "\n",
    "    Args:\n",
    "        image_list (list of PIL.Image.Image): Sequence of PIL images.\n",
    "        output_path (str): Path to save the output GIF.\n",
    "        duration (int): Duration of each frame in milliseconds (controls speed).\n",
    "        loop (int): Number of times the GIF should loop (0 for infinite).\n",
    "        background_color (tuple): RGB color to reset the background for each frame.\n",
    "    \"\"\"\n",
    "    # Determine the size of the images\n",
    "    width, height = image_list[0].size\n",
    "\n",
    "    # Ensure all frames are re-rendered on a clean background\n",
    "    cleaned_frames = []\n",
    "    for img in image_list:\n",
    "        # Create a blank canvas for each frame\n",
    "        blank_frame = Image.new(mode=img.mode, size=(width, height), color=background_color)\n",
    "        \n",
    "        # Convert the image to RGBA to handle transparency (if needed)\n",
    "        if img.mode != \"RGBA\":\n",
    "            img = img.convert(\"RGBA\")\n",
    "        \n",
    "        # Paste the current frame onto the blank canvas\n",
    "        blank_frame.paste(img, (0, 0), mask=img if img.mode == \"RGBA\" else None)\n",
    "        cleaned_frames.append(blank_frame)\n",
    "\n",
    "    # Save as GIF\n",
    "    cleaned_frames[0].save(\n",
    "        output_path,\n",
    "        save_all=True,\n",
    "        append_images=cleaned_frames[1:],\n",
    "        duration=duration,\n",
    "        loop=loop\n",
    "    )\n",
    "    print(f\"GIF saved at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "GIF saved at movie_punishment_0.75_gem_has_value_diff_models.gif\n"
     ]
    }
   ],
   "source": [
    "# from examples.puppet_training.utils import create_gif_from_arrays\n",
    "print(type(images_anim[0]) == Image.Image)\n",
    "create_gif_from_pil_force_clean(images_anim, 'movie_punishment_0.75_gem_has_value_diff_models.gif', 200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "state_punishment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
