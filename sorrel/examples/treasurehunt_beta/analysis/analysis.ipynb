{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treasure Hunt Beta Analysis\n",
        "\n",
        "This notebook provides comprehensive analysis tools for treasurehunt_beta experiments, including TensorBoard event conversion to CSV and various plotting utilities.\n",
        "\n",
        "## Features\n",
        "- Convert TensorBoard event files to CSV format\n",
        "- Plot entity comparisons across different experiment conditions\n",
        "- Generate learning curves and performance metrics\n",
        "- Create summary reports and statistical analysis\n",
        "- Support for multiple entities (Reward, Coin, Gem, Bone, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "from tensorflow.python.framework.errors_impl import DataLossError\n",
        "import tensorflow as tf\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. TensorBoard to CSV Conversion Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tensorboard_to_separate_csv(event_file, output_dir):\n",
        "    \"\"\"\n",
        "    Convert TensorBoard event file data to separate CSV files for each tag.\n",
        "    \n",
        "    Args:\n",
        "        event_file (str): Path to the TensorBoard event file.\n",
        "        output_dir (str): Directory where CSV files should be saved.\n",
        "    \"\"\"\n",
        "    tag_data = defaultdict(list)\n",
        "    \n",
        "    try:\n",
        "        for e in tf.compat.v1.train.summary_iterator(event_file):\n",
        "            try:\n",
        "                for v in e.summary.value:\n",
        "                    if v.HasField('simple_value'):\n",
        "                        tag = v.tag\n",
        "                        value = v.simple_value\n",
        "                        step = e.step\n",
        "                        tag_data[tag].append([step, value])\n",
        "            except Exception as record_error:\n",
        "                print(f\"Skipped a corrupt record in file: {event_file}\")\n",
        "    except DataLossError:\n",
        "        print(f\"Encountered DataLossError. Possibly due to incomplete writes in file: {event_file}\")\n",
        "        return\n",
        "\n",
        "    # Save tag data to CSV files\n",
        "    for tag, data_rows in tag_data.items():\n",
        "        filename = f\"{output_dir}/{tag.replace('/', '_')}_data.csv\"\n",
        "        with open(filename, 'w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(['Step', 'Value'])\n",
        "            writer.writerows(data_rows)\n",
        "        print(f\"Data for tag '{tag}' has been written to {filename}\")\n",
        "\n",
        "\n",
        "def process_tensorboard_results(parent_dir, output_parent_dir):\n",
        "    \"\"\"\n",
        "    Process all TensorBoard event files in a directory structure.\n",
        "    \n",
        "    Args:\n",
        "        parent_dir (str): Parent directory containing TensorBoard event files.\n",
        "        output_parent_dir (str): Parent directory where CSV files should be saved.\n",
        "    \"\"\"\n",
        "    for root, dirs, files in os.walk(parent_dir):\n",
        "        for file in files:\n",
        "            if \"tfevents\" in file:\n",
        "                event_file = os.path.join(root, file)\n",
        "                relative_path = os.path.relpath(root, parent_dir)\n",
        "                output_dir = os.path.join(output_parent_dir, relative_path)\n",
        "                os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "                try:\n",
        "                    tensorboard_to_separate_csv(event_file, output_dir)\n",
        "                    print(f\"Processed {event_file} -> {output_dir}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to process {event_file}: {e}\")\n",
        "\n",
        "print(\"TensorBoard conversion functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Processing Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def exponential_moving_average(data, alpha):\n",
        "    \"\"\"\n",
        "    Calculate the exponential moving average (EMA) of a 1D array.\n",
        "    \n",
        "    Args:\n",
        "        data (array-like): The input data.\n",
        "        alpha (float): The smoothing factor (0 < alpha <= 1).\n",
        "    \n",
        "    Returns:\n",
        "        numpy.ndarray: The EMA values.\n",
        "    \"\"\"\n",
        "    if not (0 < alpha <= 1):\n",
        "        raise ValueError(\"Alpha must be between 0 and 1.\")\n",
        "\n",
        "    ema = [data[0]]\n",
        "    for i in range(1, len(data)):\n",
        "        ema.append(alpha * data[i] + (1 - alpha) * ema[-1])\n",
        "    return np.array(ema)\n",
        "\n",
        "\n",
        "def rolling_average(data, window_size):\n",
        "    \"\"\"\n",
        "    Calculate the rolling average of a 1D array.\n",
        "    \n",
        "    Args:\n",
        "        data (array-like): The input data.\n",
        "        window_size (int): The size of the rolling window.\n",
        "    \n",
        "    Returns:\n",
        "        numpy.ndarray: The rolling average values.\n",
        "    \"\"\"\n",
        "    if window_size < 1:\n",
        "        raise ValueError(\"Window size must be at least 1.\")\n",
        "    if len(data) < window_size:\n",
        "        raise ValueError(\"Data length must be at least equal to the window size.\")\n",
        "    \n",
        "    weights = np.ones(window_size) / window_size\n",
        "    return np.convolve(data, weights, mode='valid')\n",
        "\n",
        "\n",
        "def trim_and_calculate_mean(array_list):\n",
        "    \"\"\"\n",
        "    Trim arrays to the same length and calculate mean.\n",
        "    \n",
        "    Args:\n",
        "        array_list (list): List of arrays to process.\n",
        "    \n",
        "    Returns:\n",
        "        numpy.ndarray: Mean of trimmed arrays.\n",
        "    \"\"\"\n",
        "    if not array_list:\n",
        "        return np.array([])\n",
        "    min_length = min(len(arr) for arr in array_list)\n",
        "    trimmed_arrays = [arr[:min_length] for arr in array_list]\n",
        "    trimmed_arrays = np.array(trimmed_arrays)\n",
        "    return trimmed_arrays\n",
        "\n",
        "\n",
        "def load_entity_data(folders, entity_name, data_dir='res'):\n",
        "    \"\"\"\n",
        "    Load data for a specific entity across multiple experiment folders.\n",
        "    \n",
        "    Args:\n",
        "        folders (list): List of folder names containing experiment data.\n",
        "        entity_name (str): Name of the entity to load (e.g., 'Reward', 'Coin').\n",
        "        data_dir (str): Directory containing the processed CSV files.\n",
        "    \n",
        "    Returns:\n",
        "        list: List of numpy arrays containing the data for each folder.\n",
        "    \"\"\"\n",
        "    collective = [[] for _ in range(len(folders))]\n",
        "    \n",
        "    for ixs, folder in enumerate(folders):\n",
        "        parent_dir = os.path.join(data_dir, folder)\n",
        "        if not os.path.exists(parent_dir):\n",
        "            print(f\"Warning: Directory {parent_dir} does not exist\")\n",
        "            continue\n",
        "            \n",
        "        items = os.listdir(parent_dir)\n",
        "        \n",
        "        for item in items:\n",
        "            if entity_name in item:\n",
        "                if os.path.isdir(os.path.join(parent_dir, item)):\n",
        "                    # Handle subdirectory case\n",
        "                    sub_dir = os.path.join(parent_dir, item)\n",
        "                    files = os.listdir(sub_dir)\n",
        "                    if files:\n",
        "                        data = pd.read_csv(os.path.join(sub_dir, files[0]))\n",
        "                        collective[ixs].append(data['Value'].to_numpy())\n",
        "                else:\n",
        "                    # Handle direct file case\n",
        "                    data = pd.read_csv(os.path.join(parent_dir, item))\n",
        "                    collective[ixs].append(data['Value'].to_numpy())\n",
        "    \n",
        "    # Process and return mean data\n",
        "    collective_processed = []\n",
        "    for i in range(len(collective)):\n",
        "        if collective[i]:  # Check if there's data\n",
        "            collective_processed.append(np.mean(trim_and_calculate_mean(collective[i]), axis=0))\n",
        "        else:\n",
        "            collective_processed.append(np.array([]))\n",
        "    \n",
        "    return collective_processed\n",
        "\n",
        "print(\"Data processing utilities defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Example Usage with TensorBoard Events\n",
        "\n",
        "Let's convert the TensorBoard event files to CSV and analyze the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Convert TensorBoard results to CSV\n",
        "print(\"Converting TensorBoard results to CSV...\")\n",
        "parent_dir = '../runs'\n",
        "output_dir = 'res'\n",
        "process_tensorboard_results(parent_dir, output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Define experiment parameters\n",
        "folders = [\n",
        "    '20250915-222233',\n",
        "    'treasurehunt_with_respawn_20250916-130915',\n",
        "    'treasurehunt_with_respawn_20250916-131121',\n",
        "    'treasurehunt_with_respawn_20250916-131609'\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    'Initial Run',\n",
        "    'Respawn Run 1',\n",
        "    'Respawn Run 2', \n",
        "    'Respawn Run 3'\n",
        "]\n",
        "\n",
        "print(f\"Analyzing {len(folders)} experiment runs:\")\n",
        "for i, (folder, label) in enumerate(zip(folders, labels)):\n",
        "    print(f\"  {i+1}. {label} ({folder})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Plotting Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_entity_comparison(folders, entity_name, labels=None, window_size=100, \n",
        "                          data_dir='res', title=None):\n",
        "    \"\"\"\n",
        "    Plot comparison of entity data across different experiment conditions.\n",
        "    \n",
        "    Args:\n",
        "        folders (list): List of folder names containing experiment data.\n",
        "        entity_name (str): Name of the entity to plot.\n",
        "        labels (list, optional): Labels for each condition.\n",
        "        window_size (int): Window size for rolling average.\n",
        "        data_dir (str): Directory containing the processed CSV files.\n",
        "        title (str, optional): Title for the plot.\n",
        "    \"\"\"\n",
        "    data = load_entity_data(folders, entity_name, data_dir)\n",
        "    \n",
        "    if labels is None:\n",
        "        labels = [f'Condition {i+1}' for i in range(len(folders))]\n",
        "    \n",
        "    if title is None:\n",
        "        title = f'{entity_name} Performance Comparison'\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(folders)))\n",
        "    \n",
        "    for ixs, d in enumerate(data):\n",
        "        if len(d) > 0:\n",
        "            smoothed_data = rolling_average(d, window_size)\n",
        "            plt.plot(smoothed_data, label=labels[ixs], alpha=0.8, color=colors[ixs], linewidth=2)\n",
        "    \n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.title(title, fontsize=16, fontweight='bold')\n",
        "    plt.ylabel(f'{entity_name} Value', fontsize=12)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_multiple_entities(folders, entities, labels=None, window_size=100, \n",
        "                          data_dir='res'):\n",
        "    \"\"\"\n",
        "    Plot multiple entities in subplots.\n",
        "    \n",
        "    Args:\n",
        "        folders (list): List of folder names containing experiment data.\n",
        "        entities (list): List of entity names to plot.\n",
        "        labels (list, optional): Labels for each condition.\n",
        "        window_size (int): Window size for rolling average.\n",
        "        data_dir (str): Directory containing the processed CSV files.\n",
        "    \"\"\"\n",
        "    n_entities = len(entities)\n",
        "    n_cols = min(3, n_entities)\n",
        "    n_rows = (n_entities + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
        "    if n_entities == 1:\n",
        "        axes = [axes]\n",
        "    elif n_rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(folders)))\n",
        "    \n",
        "    for i, entity in enumerate(entities):\n",
        "        row = i // n_cols\n",
        "        col = i % n_cols\n",
        "        ax = axes[row, col] if n_rows > 1 else axes[col]\n",
        "        \n",
        "        data = load_entity_data(folders, entity, data_dir)\n",
        "        \n",
        "        for j, d in enumerate(data):\n",
        "            if len(d) > 0:\n",
        "                smoothed_data = rolling_average(d, window_size)\n",
        "                ax.plot(smoothed_data, label=labels[j] if labels else f'Condition {j+1}', \n",
        "                       alpha=0.8, color=colors[j], linewidth=2)\n",
        "        \n",
        "        ax.set_title(f'{entity} Performance', fontweight='bold')\n",
        "        ax.set_ylabel(f'{entity} Value')\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "    \n",
        "    # Hide empty subplots\n",
        "    for i in range(n_entities, n_rows * n_cols):\n",
        "        row = i // n_cols\n",
        "        col = i % n_cols\n",
        "        ax = axes[row, col] if n_rows > 1 else axes[col]\n",
        "        ax.set_visible(False)\n",
        "    \n",
        "    plt.suptitle('Treasure Hunt Performance Metrics', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Plotting functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analysis Examples\n",
        "\n",
        "Now let's analyze the treasure hunt experiment results!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Plot individual entity comparisons\n",
        "entities_to_plot = ['Reward', 'Coin', 'Gem', 'Bone']\n",
        "\n",
        "for entity in entities_to_plot:\n",
        "    try:\n",
        "        print(f\"Plotting {entity}...\")\n",
        "        plot_entity_comparison(folders, entity, labels, window_size=50, \n",
        "                             title=f'{entity} Performance Comparison')\n",
        "    except Exception as e:\n",
        "        print(f\"Could not plot {entity}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: Plot multiple entities in subplots\n",
        "print(\"Creating multi-entity comparison plot...\")\n",
        "try:\n",
        "    plot_multiple_entities(folders, entities_to_plot, labels, window_size=50)\n",
        "except Exception as e:\n",
        "    print(f\"Could not create multi-entity plot: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: Load and analyze specific entity data\n",
        "print(\"Loading Reward data for detailed analysis...\")\n",
        "reward_data = load_entity_data(folders, 'Reward')\n",
        "\n",
        "print(\"\\nReward Statistics:\")\n",
        "print(\"-\" * 50)\n",
        "for i, (folder, data) in enumerate(zip(folders, reward_data)):\n",
        "    if len(data) > 0:\n",
        "        print(f\"{labels[i]} ({folder}):\")\n",
        "        print(f\"  - Final reward: {data[-1]:.4f}\")\n",
        "        print(f\"  - Max reward: {data.max():.4f}\")\n",
        "        print(f\"  - Min reward: {data.min():.4f}\")\n",
        "        print(f\"  - Mean reward: {data.mean():.4f}\")\n",
        "        print(f\"  - Std reward: {data.std():.4f}\")\n",
        "        print(f\"  - Data points: {len(data)}\")\n",
        "    else:\n",
        "        print(f\"{labels[i]} ({folder}): No data available\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 4: Compare different smoothing methods\n",
        "print(\"Comparing different smoothing methods for Reward data...\")\n",
        "\n",
        "# Load reward data for the first available run\n",
        "reward_data = load_entity_data(folders, 'Reward')\n",
        "if len(reward_data) > 0 and len(reward_data[0]) > 0:\n",
        "    data = reward_data[0]  # Use first run's data\n",
        "    \n",
        "    plt.figure(figsize=(15, 5))\n",
        "    \n",
        "    # Original data\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(data[:1000], alpha=0.7, label='Original', color='blue')\n",
        "    plt.title('Original Data (first 1000 points)')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Rolling average\n",
        "    plt.subplot(1, 3, 2)\n",
        "    window_size = 50\n",
        "    smoothed_rolling = rolling_average(data, window_size)\n",
        "    plt.plot(smoothed_rolling[:1000], label=f'Rolling Average (window={window_size})', color='red')\n",
        "    plt.title('Rolling Average')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Exponential moving average\n",
        "    plt.subplot(1, 3, 3)\n",
        "    alpha = 0.1\n",
        "    smoothed_ema = exponential_moving_average(data, alpha)\n",
        "    plt.plot(smoothed_ema[:1000], label=f'EMA (Î±={alpha})', color='green')\n",
        "    plt.title('Exponential Moving Average')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No reward data available for comparison\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary Report Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_summary_report(folders, entities, labels=None, data_dir='res'):\n",
        "    \"\"\"\n",
        "    Generate a summary report of the experiment results.\n",
        "    \n",
        "    Args:\n",
        "        folders (list): List of folder names containing experiment data.\n",
        "        entities (list): List of entity names to analyze.\n",
        "        labels (list, optional): Labels for each condition.\n",
        "        data_dir (str): Directory containing the processed CSV files.\n",
        "    \"\"\"\n",
        "    if labels is None:\n",
        "        labels = [f'Condition {i+1}' for i in range(len(folders))]\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"TREASURE HUNT EXPERIMENT ANALYSIS REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Generated on: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"Number of conditions: {len(folders)}\")\n",
        "    print(f\"Entities analyzed: {', '.join(entities)}\")\n",
        "    print()\n",
        "    \n",
        "    for entity in entities:\n",
        "        print(f\"## {entity} Analysis\")\n",
        "        print(\"-\" * 40)\n",
        "        data = load_entity_data(folders, entity, data_dir)\n",
        "        \n",
        "        for i, (folder, d) in enumerate(zip(folders, data)):\n",
        "            if len(d) > 0:\n",
        "                final_value = d[-1]\n",
        "                max_value = np.max(d)\n",
        "                min_value = np.min(d)\n",
        "                mean_value = np.mean(d)\n",
        "                std_value = np.std(d)\n",
        "                \n",
        "                print(f\"### {labels[i]} ({folder})\")\n",
        "                print(f\"- Final value: {final_value:.4f}\")\n",
        "                print(f\"- Maximum value: {max_value:.4f}\")\n",
        "                print(f\"- Minimum value: {min_value:.4f}\")\n",
        "                print(f\"- Mean value: {mean_value:.4f}\")\n",
        "                print(f\"- Standard deviation: {std_value:.4f}\")\n",
        "                print(f\"- Data points: {len(d)}\")\n",
        "                print()\n",
        "            else:\n",
        "                print(f\"### {labels[i]} ({folder})\")\n",
        "                print(\"- No data available\")\n",
        "                print()\n",
        "\n",
        "# Generate the summary report\n",
        "print(\"Generating summary report...\")\n",
        "generate_summary_report(folders, entities_to_plot, labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Custom Analysis Examples\n",
        "\n",
        "You can modify these examples or create your own analysis based on your specific needs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Custom analysis - Compare final performance across runs\n",
        "print(\"Custom Analysis: Final Performance Comparison\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load all entity data\n",
        "all_data = {}\n",
        "for entity in entities_to_plot:\n",
        "    all_data[entity] = load_entity_data(folders, entity)\n",
        "\n",
        "# Create a comparison table\n",
        "comparison_data = []\n",
        "for i, (folder, label) in enumerate(zip(folders, labels)):\n",
        "    row = {'Run': label, 'Folder': folder}\n",
        "    for entity in entities_to_plot:\n",
        "        if len(all_data[entity][i]) > 0:\n",
        "            row[f'{entity}_Final'] = all_data[entity][i][-1]\n",
        "            row[f'{entity}_Max'] = all_data[entity][i].max()\n",
        "        else:\n",
        "            row[f'{entity}_Final'] = 'N/A'\n",
        "            row[f'{entity}_Max'] = 'N/A'\n",
        "    comparison_data.append(row)\n",
        "\n",
        "# Display as a table\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(df_comparison.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Notes and Tips\n",
        "\n",
        "- **Data Directory**: The analysis assumes TensorBoard event files are in `../runs` and CSV files are saved to `res/`\n",
        "- **Window Size**: Adjust the `window_size` parameter for different smoothing levels (smaller = more detail, larger = smoother)\n",
        "- **Entities**: Modify the `entities_to_plot` list to analyze different metrics\n",
        "- **Labels**: Update the `labels` list to match your experiment conditions\n",
        "- **Error Handling**: The code includes try-catch blocks to handle missing data gracefully\n",
        "\n",
        "### Common Issues:\n",
        "- If you get \"No data available\" errors, check that the CSV files were created correctly\n",
        "- If plots are empty, verify that the entity names match those in your TensorBoard logs\n",
        "- If smoothing looks too aggressive, reduce the `window_size` parameter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
